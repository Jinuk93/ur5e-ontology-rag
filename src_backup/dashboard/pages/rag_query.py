# ============================================================
# src/dashboard/pages/rag_query.py - UR5e ê¸°ìˆ  ì§€ì› ì‹œìŠ¤í…œ
# ============================================================
# UX ê°œì„  v7: í¬ë§· ìˆ˜ì •, íŒ¨í„´ ìƒì„¸, ì˜ˆì œ ì§ˆë¬¸ ë‹¤ì–‘í™”
# ============================================================

import streamlit as st
from datetime import datetime, timedelta
import os
import sys

# Add project root to path for imports
_project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
if _project_root not in sys.path:
    sys.path.insert(0, _project_root)

from src.dashboard.services.api_client import api_client
from src.dashboard.components.evidence import render_evidence_panel
from src.dashboard.utils.formatters import format_latency, format_confidence, get_verification_badge


# ============================================================
# ì˜ˆì œ ì§ˆë¬¸ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì—ëŸ¬ì½”ë“œ ë²”ìœ„ C0~C55 ê¸°ë°˜ + ë‹¤ì–‘í™”)
# ============================================================

SAMPLE_QUESTIONS = [
    # === ì—ëŸ¬ ì½”ë“œ (C0~C55 ë²”ìœ„ ë‚´ ë‹¤ì–‘í•œ ì½”ë“œ) ===
    {"q": "C10 ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì›ì¸ê³¼ í•´ê²°ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.", "cat": "ì—ëŸ¬ì½”ë“œ", "desc": "ë¡œë´‡ ë¹„ìƒì •ì§€"},
    {"q": "C23 ì—ëŸ¬ê°€ ë°˜ë³µë©ë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?", "cat": "ì—ëŸ¬ì½”ë“œ", "desc": "ì¡°ì¸íŠ¸ í†µì‹  ì˜¤ë¥˜"},
    {"q": "C35 ì—ëŸ¬ ì½”ë“œì˜ ì˜ë¯¸ì™€ ì¡°ì¹˜ ë°©ë²•", "cat": "ì—ëŸ¬ì½”ë“œ", "desc": "ì•ˆì „ ì‹œìŠ¤í…œ ì˜¤ë¥˜"},
    {"q": "C99 ì—ëŸ¬ê°€ ë°œìƒí–ˆëŠ”ë° ì½”ë“œë¥¼ ëª» ì°¾ê² ì–´ìš”", "cat": "ì—ëŸ¬ì½”ë“œ", "desc": "ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬"},

    # === ì¦ìƒ ê¸°ë°˜ ===
    {"q": "ë¡œë´‡ì´ ì‘ì—… ì¤‘ ê°‘ìê¸° ë©ˆì·„ì–´ìš”", "cat": "ì¦ìƒ", "desc": "ê¸‰ì •ì§€ ì¦ìƒ"},
    {"q": "ë¡œë´‡ íŒ”ì—ì„œ ì§„ë™ì´ ëŠê»´ì§‘ë‹ˆë‹¤", "cat": "ì¦ìƒ", "desc": "ì§„ë™ ì¦ìƒ"},
    {"q": "ë¡œë´‡ì—ì„œ í‰ì†Œì™€ ë‹¤ë¥¸ ì†Œë¦¬ê°€ ë‚©ë‹ˆë‹¤", "cat": "ì¦ìƒ", "desc": "ì´ìƒ ì†ŒìŒ"},
    {"q": "íŠ¹ì • ì¡°ì¸íŠ¸ê°€ ëœ¨ê²ìŠµë‹ˆë‹¤", "cat": "ì¦ìƒ", "desc": "ê³¼ì—´ ì¦ìƒ"},

    # === ë¶€í’ˆ/êµ¬ì„±ìš”ì†Œ ===
    {"q": "Joint 3ì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” ì—ëŸ¬ì™€ í•´ê²°ë²•", "cat": "ë¶€í’ˆ", "desc": "ì¡°ì¸íŠ¸3 ê´€ë ¨"},
    {"q": "Control Box ê´€ë ¨ ì—ëŸ¬ ì¢…ë¥˜ì™€ ëŒ€ì²˜ë²•", "cat": "ë¶€í’ˆ", "desc": "ì»¨íŠ¸ë¡¤ë°•ìŠ¤ ê´€ë ¨"},
    {"q": "Tool Flange ì—°ê²° ë¬¸ì œ í•´ê²°", "cat": "ë¶€í’ˆ", "desc": "íˆ´í”Œëœì§€ ê´€ë ¨"},
    {"q": "Safety IO ì„¤ì • ë° ì˜¤ë¥˜ í•´ê²°", "cat": "ë¶€í’ˆ", "desc": "ì•ˆì „IO ê´€ë ¨"},

    # === ì„¼ì„œ ë°ì´í„° ë¶„ì„ ===
    {"q": "Fz ê°’ì´ 100Nì„ ì´ˆê³¼í–ˆì„ ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œ", "cat": "ì„¼ì„œë°ì´í„°", "desc": "Zì¶• í˜ ì´ˆê³¼"},
    {"q": "Tx, Ty í† í¬ê°’ì´ ê¸‰ê²©íˆ ë³€í•  ë•Œ ì›ì¸", "cat": "ì„¼ì„œë°ì´í„°", "desc": "í† í¬ ê¸‰ë³€"},
    {"q": "ì„¼ì„œì—ì„œ ì¶©ëŒ íŒ¨í„´ì´ ê°ì§€ëìŠµë‹ˆë‹¤", "cat": "ì„¼ì„œë°ì´í„°", "desc": "ì¶©ëŒ íŒ¨í„´"},
    {"q": "ì§„ë™ íŒ¨í„´ ê°ì§€ ì‹œ í™•ì¸ ì‚¬í•­", "cat": "ì„¼ì„œë°ì´í„°", "desc": "ì§„ë™ íŒ¨í„´"},

    # === ë§¤ë‰´ì–¼/ìš´ì˜ ===
    {"q": "ë¡œë´‡ ì •ê¸° ì ê²€ ì£¼ê¸°ì™€ í•­ëª©", "cat": "ë§¤ë‰´ì–¼", "desc": "ìœ ì§€ë³´ìˆ˜ ê°€ì´ë“œ"},
    {"q": "Freedrive ëª¨ë“œ ì§„ì… ë° ì‚¬ìš©ë²•", "cat": "ë§¤ë‰´ì–¼", "desc": "í”„ë¦¬ë“œë¼ì´ë¸Œ"},
    {"q": "ë¸Œë ˆì´í¬ ìˆ˜ë™ í•´ì œ ì ˆì°¨", "cat": "ë§¤ë‰´ì–¼", "desc": "ë¸Œë ˆì´í¬ í•´ì œ"},
    {"q": "ë¹„ìƒì •ì§€ í›„ ì•ˆì „í•˜ê²Œ ì¬ì‹œì‘í•˜ëŠ” ë°©ë²•", "cat": "ë§¤ë‰´ì–¼", "desc": "ì¬ì‹œì‘ ì ˆì°¨"},
]

MAX_CONVERSATION_TABS = 5


def execute_query(question: str, strategy: str, top_k: int, include_sources: bool):
    """ì§ˆë¬¸ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜"""
    result = api_client.query(
        question=question,
        top_k=top_k,
        include_sources=include_sources,
        include_citation=True,
        strategy=strategy,
    )
    return result


def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "conversations" not in st.session_state:
        st.session_state.conversations = {
            0: {"name": "ëŒ€í™” 1", "history": [], "last_result": None}
        }
    if "current_conv_id" not in st.session_state:
        st.session_state.current_conv_id = 0
    if "next_conv_id" not in st.session_state:
        st.session_state.next_conv_id = 1
    if "pending_question" not in st.session_state:
        st.session_state.pending_question = None
    if "selected_pattern" not in st.session_state:
        st.session_state.selected_pattern = None


def get_current_conversation():
    """í˜„ì¬ ì„ íƒëœ ëŒ€í™” ê°€ì ¸ì˜¤ê¸°"""
    conv_id = st.session_state.current_conv_id
    if conv_id not in st.session_state.conversations:
        st.session_state.conversations[conv_id] = {
            "name": f"ëŒ€í™” {conv_id + 1}",
            "history": [],
            "last_result": None
        }
    return st.session_state.conversations[conv_id]


def add_new_conversation():
    """ìƒˆ ëŒ€í™” ì¶”ê°€"""
    if len(st.session_state.conversations) >= MAX_CONVERSATION_TABS:
        st.toast(f"ìµœëŒ€ {MAX_CONVERSATION_TABS}ê°œ ëŒ€í™”ê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        return

    new_id = st.session_state.next_conv_id
    st.session_state.conversations[new_id] = {
        "name": f"ëŒ€í™” {new_id + 1}",
        "history": [],
        "last_result": None
    }
    st.session_state.current_conv_id = new_id
    st.session_state.next_conv_id += 1


def render_sensor_monitoring():
    """ì„¼ì„œ ì¸¡ì • ë°ì´í„° ëª¨ë‹ˆí„°ë§"""
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots

    st.markdown("### ğŸ“Š ì„¼ì„œ ì¸¡ì • í˜„í™© (Axia80 í˜/í† í¬ ì„¼ì„œ)")
    st.caption("**Fz** : Zì¶• í˜ (ìˆ˜ì§ ë°©í–¥, ë‹¨ìœ„: N) | **Tx** : Xì¶• í† í¬ (ë‹¨ìœ„: Nm) | **Ty** : Yì¶• í† í¬ (ë‹¨ìœ„: Nm)")

    # 7ì¼ì¹˜ ë‚ ì§œ
    end_date = datetime.now()
    start_date = end_date - timedelta(days=6)
    dates = [(datetime.now() - timedelta(days=i)).strftime("%m/%d") for i in range(6, -1, -1)]
    date_range = f"{start_date.strftime('%Y.%m.%d')} ~ {end_date.strftime('%Y.%m.%d')}"

    # ì„¼ì„œ ì¸¡ì •ê°’ (ì‹œë®¬ë ˆì´ì…˜)
    fz_avg = [23.5, 25.2, 24.8, 26.1, 24.5, 25.8, 27.2]
    fz_max = [45.2, 52.8, 48.3, 55.1, 47.6, 51.2, 58.4]
    fz_min = [5.1, 4.8, 5.3, 4.9, 5.2, 4.7, 5.0]
    tx_avg = [1.2, 1.4, 1.3, 1.5, 1.3, 1.4, 1.6]
    ty_avg = [0.8, 0.9, 0.85, 0.95, 0.88, 0.92, 1.0]

    # íŒ¨í„´ ìƒì„¸ ë°ì´í„°
    pattern_details = {
        "ì¶©ëŒ": [
            {"date": dates[0], "time": "14:23:15", "fz": 82.5, "tx": 3.2, "ty": 2.8},
            {"date": dates[2], "time": "09:15:42", "fz": 78.3, "tx": 2.9, "ty": 3.1},
            {"date": dates[2], "time": "16:45:08", "fz": 85.1, "tx": 3.5, "ty": 2.6},
            {"date": dates[4], "time": "11:32:21", "fz": 79.8, "tx": 3.0, "ty": 2.9},
            {"date": dates[6], "time": "08:17:33", "fz": 81.2, "tx": 3.3, "ty": 2.7},
        ],
        "ì§„ë™": [
            {"date": dates[1], "time": "10:45:22", "fz": 28.3, "tx": 4.2, "ty": 3.8},
            {"date": dates[3], "time": "15:22:11", "fz": 31.5, "tx": 4.5, "ty": 4.1},
            {"date": dates[4], "time": "13:18:45", "fz": 29.8, "tx": 4.8, "ty": 3.9},
            {"date": dates[4], "time": "17:55:33", "fz": 32.1, "tx": 4.3, "ty": 4.2},
            {"date": dates[5], "time": "09:30:15", "fz": 30.2, "tx": 4.6, "ty": 4.0},
        ],
        "ê³¼ë¶€í•˜": [
            {"date": dates[2], "time": "12:33:18", "fz": 95.2, "tx": 5.1, "ty": 4.8},
            {"date": dates[5], "time": "14:45:22", "fz": 98.5, "tx": 5.3, "ty": 5.0},
        ],
        "ë“œë¦¬í”„íŠ¸": [
            {"date": dates[0], "time": "16:12:45", "fz": 35.2, "tx": 1.8, "ty": 1.5},
            {"date": dates[3], "time": "11:22:33", "fz": 36.8, "tx": 1.9, "ty": 1.6},
            {"date": dates[6], "time": "10:15:28", "fz": 34.5, "tx": 1.7, "ty": 1.4},
        ],
    }

    patterns = {
        "ì¶©ëŒ": [1, 0, 2, 0, 1, 0, 1],
        "ì§„ë™": [0, 1, 0, 1, 2, 1, 0],
        "ê³¼ë¶€í•˜": [0, 0, 1, 0, 0, 1, 0],
        "ë“œë¦¬í”„íŠ¸": [1, 0, 0, 1, 0, 0, 1],
    }

    total_records = 7 * 24 * 360

    col1, col2 = st.columns([2.5, 1])

    with col1:
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=("í˜ ì¸¡ì •ê°’ (Fz) - N", "í† í¬ ì¸¡ì •ê°’ (Tx, Ty) - Nm"),
            vertical_spacing=0.18,
            row_heights=[0.5, 0.5]
        )

        fig.add_trace(go.Scatter(name="Fz í‰ê· ", x=dates, y=fz_avg, mode="lines+markers",
                      line=dict(color="#2196F3", width=2), marker=dict(size=8)), row=1, col=1)
        fig.add_trace(go.Scatter(name="Fz ìµœëŒ€", x=dates, y=fz_max, mode="lines",
                      line=dict(color="#f44336", width=1, dash="dot")), row=1, col=1)
        fig.add_trace(go.Scatter(name="Fz ìµœì†Œ", x=dates, y=fz_min, mode="lines",
                      line=dict(color="#4CAF50", width=1, dash="dot")), row=1, col=1)
        fig.add_trace(go.Scatter(name="Tx í‰ê· ", x=dates, y=tx_avg, mode="lines+markers",
                      line=dict(color="#FF9800", width=2), marker=dict(size=8)), row=2, col=1)
        fig.add_trace(go.Scatter(name="Ty í‰ê· ", x=dates, y=ty_avg, mode="lines+markers",
                      line=dict(color="#9C27B0", width=2), marker=dict(size=8)), row=2, col=1)

        fig.update_layout(height=300, margin=dict(l=20, r=20, t=35, b=20),
                         legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                         font=dict(size=10))
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.markdown(f"<p style='font-size:11px; color:#888;'>ê¸°ê°„ : {date_range}</p>", unsafe_allow_html=True)

        latest_fz = fz_avg[-1]
        status_icon = "ğŸŸ¢" if latest_fz < 30 else "ğŸŸ¡" if latest_fz < 50 else "ğŸ”´"
        status_text = "ì •ìƒ" if latest_fz < 30 else "ì£¼ì˜" if latest_fz < 50 else "ê²½ê³ "

        st.markdown(f"""
        <div style="font-size:12px;">
            <b>ìƒíƒœ</b> : {status_icon} {status_text}<br>
            <b>Fz í‰ê· </b> : {fz_avg[-1]:.1f} N <span style="color:{'#4CAF50' if fz_avg[-1]-fz_avg[-2] < 0 else '#f44336'}">({fz_avg[-1]-fz_avg[-2]:+.1f})</span><br>
            <b>Fz ìµœëŒ€</b> : {fz_max[-1]:.1f} N<br>
            <b>ì´ ë ˆì½”ë“œ</b> : {total_records:,}ê°œ
        </div>
        """, unsafe_allow_html=True)

    # íŒ¨í„´ ê°ì§€ í˜„í™©
    st.markdown("**ê°ì§€ëœ ì´ìƒ íŒ¨í„´ (7ì¼ê°„)**")

    pattern_cols = st.columns(4)
    pattern_colors = {"ì¶©ëŒ": "#f44336", "ì§„ë™": "#FF9800", "ê³¼ë¶€í•˜": "#9C27B0", "ë“œë¦¬í”„íŠ¸": "#2196F3"}

    for i, (pattern_name, counts) in enumerate(patterns.items()):
        with pattern_cols[i]:
            total = sum(counts)
            today = counts[-1]
            color = pattern_colors[pattern_name]

            if st.button(f"{pattern_name} : {total}ê±´", key=f"pattern_{pattern_name}", use_container_width=True):
                st.session_state.selected_pattern = pattern_name if st.session_state.selected_pattern != pattern_name else None
                st.rerun()

    # ì„ íƒëœ íŒ¨í„´ ìƒì„¸ í‘œì‹œ
    if st.session_state.selected_pattern and st.session_state.selected_pattern in pattern_details:
        pattern_name = st.session_state.selected_pattern
        details = pattern_details[pattern_name]
        color = pattern_colors[pattern_name]

        st.markdown(f"""
        <div style="background-color: {color}15; padding: 12px; border-radius: 8px; border-left: 4px solid {color}; margin-top: 8px;">
            <b>{pattern_name} íŒ¨í„´ ìƒì„¸ ({len(details)}ê±´)</b>
        </div>
        """, unsafe_allow_html=True)

        detail_cols = st.columns(len(details))
        for j, detail in enumerate(details):
            with detail_cols[j]:
                st.markdown(f"""
                <div style="font-size:11px; background:#f5f5f5; padding:8px; border-radius:4px; text-align:center;">
                    <b>{detail['date']}</b><br>
                    {detail['time']}<br>
                    Fz: {detail['fz']}N<br>
                    Tx: {detail['tx']}Nm
                </div>
                """, unsafe_allow_html=True)


def render_source_with_excerpt(source: dict, index: int):
    """ë°œì·Œê¸€ì´ í¬í•¨ëœ ì†ŒìŠ¤ ì¹´ë“œ ë Œë”ë§"""
    score = source.get("score", 0)
    name = source.get("name", source.get("metadata", {}).get("entity_name", "ì•Œ ìˆ˜ ì—†ìŒ"))
    src_type = source.get("type", source.get("source_type", "unknown"))
    content = source.get("content", source.get("text", source.get("metadata", {}).get("content", "")))

    type_name = "ì§€ì‹ê·¸ë˜í”„" if src_type == "graph" else "ë¬¸ì„œDB"
    type_icon = "ğŸ”·" if src_type == "graph" else "ğŸ“„"
    type_color = "#2196F3" if src_type == "graph" else "#4CAF50"
    badge = "ë†’ìŒ" if score >= 0.7 else "ë³´í†µ" if score >= 0.4 else "ë‚®ìŒ"

    with st.expander(f"{type_icon} [{index}] {name} - ì‹ ë¢°ë„ : {score*100:.0f}% ({badge})", expanded=True):
        st.markdown(f"**ì¶œì²˜** : {type_name} | **ì‹ ë¢°ë„** : {score*100:.1f}%")

        if content:
            st.markdown(f"""
            <div style="background-color: #f5f5f5; border-left: 4px solid {type_color};
                        padding: 10px 14px; margin: 8px 0; border-radius: 4px; font-size: 13px;">
                {content[:400]}{'...' if len(content) > 400 else ''}
            </div>
            """, unsafe_allow_html=True)
        else:
            st.caption("ë°œì·Œ ë‚´ìš© ì—†ìŒ")


def render_rag_query():
    """UR5e ê¸°ìˆ  ì§€ì› ì‹œìŠ¤í…œ ë©”ì¸ í˜ì´ì§€"""

    initialize_session_state()

    st.markdown("""
    <style>
    .stChatInput textarea { font-size: 16px !important; min-height: 50px !important; }
    .stChatInput textarea::placeholder { text-align: left !important; }
    </style>
    """, unsafe_allow_html=True)

    # ============================================================
    # 1. ì œëª© ë° ê°€ì´ë“œ (í•­ìƒ í¼ì¹¨, í¬ë§· ìˆ˜ì •)
    # ============================================================

    st.title("UR5e ê¸°ìˆ  ì§€ì› ì‹œìŠ¤í…œ")

    with st.expander("ğŸ“– í”„ë¡œì íŠ¸ ì†Œê°œ ë° ì‚¬ìš© ê°€ì´ë“œ", expanded=True):
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("""
            **í”„ë¡œì íŠ¸ ë°°ê²½**

            UR5e í˜‘ë™ ë¡œë´‡ì˜ ì—ëŸ¬ ì§„ë‹¨ ë° í•´ê²° ì§€ì› ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

            í˜„ì¥ì—ì„œ ì—ëŸ¬ ë°œìƒ ì‹œ ë§¤ë‰´ì–¼ ê²€ìƒ‰, ì „ë¬¸ê°€ ë¬¸ì˜ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.

            **ë°ì´í„° êµ¬ì„±**
            - ì§€ì‹ê·¸ë˜í”„ : ì—ëŸ¬ 170ê°œ, ì›ì¸ 85ê°œ, í•´ê²°ì±… 120ê°œ
            - ë¬¸ì„œDB : ë§¤ë‰´ì–¼ 1,750 ì²­í¬
            - ì„¼ì„œDB : 7ì¼ê°„ 60,480 ë ˆì½”ë“œ
            """)

        with col2:
            st.markdown("""
            **êµ¬í˜„ ê¸°ëŠ¥**

            | ê¸°ëŠ¥ | ì„¤ëª… |
            |------|------|
            | ì—ëŸ¬ì½”ë“œ ê²€ìƒ‰ | ì—ëŸ¬ì½”ë“œ ì…ë ¥ ì‹œ ì›ì¸, í•´ê²°ì±…, ê´€ë ¨ ë¶€í’ˆì„ ì§€ì‹ê·¸ë˜í”„ì—ì„œ íƒìƒ‰ |
            | ì¦ìƒ ê¸°ë°˜ ê²€ìƒ‰ | ìì—°ì–´ ì¦ìƒ ì„¤ëª…ìœ¼ë¡œ ê´€ë ¨ ì—ëŸ¬ì½”ë“œ í›„ë³´ ì œì‹œ |
            | ë§¤ë‰´ì–¼ ê²€ìƒ‰ | UR5e ë§¤ë‰´ì–¼ì—ì„œ ìœ ì‚¬ ë‚´ìš© ê²€ìƒ‰ |
            | ì„¼ì„œ ì—°ê³„ ë¶„ì„ | Fz/Tx/Ty ì¸¡ì •ê°’ê³¼ ì—ëŸ¬ íŒ¨í„´ ì—°ê³„ |
            """)

        with col3:
            st.markdown("""
            **í…ŒìŠ¤íŠ¸ ë°©ë²•**

            1. **ì—ëŸ¬ì½”ë“œ** : "C10 ì—ëŸ¬" ì…ë ¥
            2. **ì¦ìƒ** : "ë¡œë´‡ì´ ë©ˆì·„ì–´ìš”" ì…ë ¥
            3. **ë¶€í’ˆ** : "Joint 3 ì—ëŸ¬" ì…ë ¥
            4. **ì„¼ì„œ** : "Fz ê°’ì´ ë†’ì„ ë•Œ" ì…ë ¥

            ì•„ë˜ ì˜ˆì œ ì§ˆë¬¸ì„ í´ë¦­í•˜ë©´ ë°”ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            """)

    st.divider()

    # ============================================================
    # 2. ì„¼ì„œ ì¸¡ì • ë°ì´í„° ëª¨ë‹ˆí„°ë§
    # ============================================================

    render_sensor_monitoring()

    st.divider()

    # ============================================================
    # 3. ëŒ€í™” íƒ­
    # ============================================================

    st.markdown("### ëŒ€í™” ëª©ë¡")

    conv_cols = st.columns(MAX_CONVERSATION_TABS + 1)

    for i, (conv_id, conv_data) in enumerate(st.session_state.conversations.items()):
        with conv_cols[i]:
            is_current = conv_id == st.session_state.current_conv_id
            btn_type = "primary" if is_current else "secondary"
            label = conv_data["name"]
            if conv_data["history"]:
                label += f" ({len(conv_data['history'])//2})"

            if st.button(label, key=f"conv_tab_{conv_id}", type=btn_type, use_container_width=True):
                st.session_state.current_conv_id = conv_id
                st.rerun()

    with conv_cols[len(st.session_state.conversations)]:
        if len(st.session_state.conversations) < MAX_CONVERSATION_TABS:
            if st.button("+ ìƒˆ ëŒ€í™”", key="add_conv", use_container_width=True):
                add_new_conversation()
                st.rerun()

    st.divider()

    # ============================================================
    # 4. ì§ˆë¬¸ ì…ë ¥
    # ============================================================

    user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

    if st.session_state.pending_question:
        user_input = st.session_state.pending_question
        st.session_state.pending_question = None

    # ============================================================
    # 5. ì˜ˆì œ ì§ˆë¬¸
    # ============================================================

    with st.expander("ğŸ’¡ ì˜ˆì œ ì§ˆë¬¸  (í´ë¦­í•˜ë©´ ë°”ë¡œ ë‹µë³€)", expanded=True):

        cat_tabs = st.tabs(["ì—ëŸ¬ì½”ë“œ", "ì¦ìƒ", "ë¶€í’ˆ", "ì„¼ì„œë°ì´í„°", "ë§¤ë‰´ì–¼"])
        categories = ["ì—ëŸ¬ì½”ë“œ", "ì¦ìƒ", "ë¶€í’ˆ", "ì„¼ì„œë°ì´í„°", "ë§¤ë‰´ì–¼"]

        tab_descriptions = {
            "ì—ëŸ¬ì½”ë“œ": "í™”ë©´ì— í‘œì‹œëœ ì—ëŸ¬ì½”ë“œ(C10, C23 ë“±)ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì›ì¸, í•´ê²°ì±…, ê´€ë ¨ ë¶€í’ˆ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
            "ì¦ìƒ": "ë¡œë´‡ì—ì„œ ê´€ì°°ëœ ì¦ìƒì„ ì„¤ëª…í•˜ì„¸ìš”. ê´€ë ¨ ì—ëŸ¬ì½”ë“œì™€ ì ê²€ ì‚¬í•­ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.",
            "ë¶€í’ˆ": "ë¬¸ì œê°€ ë°œìƒí•œ ë¶€í’ˆëª…(Joint, Control Box ë“±)ì„ ì…ë ¥í•˜ì„¸ìš”.",
            "ì„¼ì„œë°ì´í„°": "Axia80 ì„¼ì„œ ì¸¡ì •ê°’(Fz, Tx, Ty) ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ì„¸ìš”. íŒ¨í„´ê³¼ ì—ëŸ¬ë¥¼ ì—°ê³„ ë¶„ì„í•©ë‹ˆë‹¤.",
            "ë§¤ë‰´ì–¼": "UR5e ìš´ì˜, ìœ ì§€ë³´ìˆ˜, ì„¤ì • ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ì„¸ìš”."
        }

        for cat_tab, category in zip(cat_tabs, categories):
            with cat_tab:
                st.caption(tab_descriptions[category])

                questions = [q for q in SAMPLE_QUESTIONS if q["cat"] == category]
                cols = st.columns(2)
                for i, q_data in enumerate(questions):
                    with cols[i % 2]:
                        if st.button(q_data['q'], key=f"q_{category}_{i}", use_container_width=True, help=q_data['desc']):
                            st.session_state.pending_question = q_data['q']
                            st.rerun()

    st.divider()

    # ============================================================
    # 6. ëŒ€í™” ì˜ì—­
    # ============================================================

    current_conv = get_current_conversation()
    st.markdown(f"### {current_conv['name']}")

    for msg in current_conv["history"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

            if msg["role"] == "assistant" and msg.get("meta"):
                meta = msg["meta"]
                col1, col2, col3 = st.columns(3)
                with col1:
                    conf = meta.get("confidence", 0)
                    conf_icon = "ğŸŸ¢" if conf >= 0.7 else "ğŸŸ¡" if conf >= 0.4 else "ğŸ”´"
                    st.caption(f"{conf_icon} ì‹ ë¢°ë„ : {conf*100:.0f}%")
                with col2:
                    st.caption(f"ì‘ë‹µì‹œê°„ : {meta.get('latency', 0):.0f}ms")
                with col3:
                    status = meta.get("status", "unknown")
                    status_text = {"verified": "ê²€ì¦ë¨", "partial": "ë¶€ë¶„ê²€ì¦", "unverified": "ë¯¸ê²€ì¦"}.get(status, status)
                    st.caption(f"ìƒíƒœ : {status_text}")

                # ê° ë‹µë³€ë³„ ê·¼ê±° í† ê¸€
                if msg.get("sources"):
                    with st.expander("ğŸ“š ë‹µë³€ ê·¼ê±° ìƒì„¸", expanded=False):
                        for i, src in enumerate(msg["sources"], 1):
                            render_source_with_excerpt(src, i)

    # ============================================================
    # 7. ì§ˆë¬¸ ì²˜ë¦¬
    # ============================================================

    strategy = "hybrid"
    top_k = 5
    include_sources = True

    if user_input:
        current_conv["history"].append({"role": "user", "content": user_input})

        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                result = execute_query(user_input, strategy, top_k, include_sources)

                if result.success:
                    st.markdown(result.answer)

                    verification = result.verification or {}
                    conf = verification.get("confidence", 0)

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        conf_icon = "ğŸŸ¢" if conf >= 0.7 else "ğŸŸ¡" if conf >= 0.4 else "ğŸ”´"
                        st.caption(f"{conf_icon} ì‹ ë¢°ë„ : {conf*100:.0f}%")
                    with col2:
                        st.caption(f"ì‘ë‹µì‹œê°„ : {result.latency_ms:.0f}ms")
                    with col3:
                        status = verification.get("status", "unknown")
                        status_text = {"verified": "ê²€ì¦ë¨", "partial": "ë¶€ë¶„ê²€ì¦", "unverified": "ë¯¸ê²€ì¦"}.get(status, status)
                        st.caption(f"ìƒíƒœ : {status_text}")

                    # ìƒˆ ë‹µë³€ì—ë„ ê·¼ê±° í† ê¸€ ì¶”ê°€
                    if include_sources and result.sources:
                        with st.expander("ğŸ“š ë‹µë³€ ê·¼ê±° ìƒì„¸", expanded=False):
                            for i, source in enumerate(result.sources, 1):
                                render_source_with_excerpt(source, i)

                    current_conv["history"].append({
                        "role": "assistant",
                        "content": result.answer,
                        "meta": {"confidence": conf, "latency": result.latency_ms, "status": verification.get("status", "unknown")},
                        "sources": result.sources if include_sources else [],
                    })
                    current_conv["last_result"] = result
                else:
                    error_msg = f"ì˜¤ë¥˜ : {result.error}"
                    st.error(error_msg)
                    current_conv["history"].append({"role": "assistant", "content": error_msg})

    # ============================================================
    # 8. í•˜ë‹¨ ë²„íŠ¼ (ë‹µë³€ ê·¼ê±° ìƒì„¸ ì„¹ì…˜ ì œê±°ë¨ - ê° ë‹µë³€ì— ê°œë³„ í† ê¸€ë¡œ ì´ë™)
    # ============================================================

    st.divider()
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        if st.button("ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
            current_conv["history"] = []
            current_conv["last_result"] = None
            st.rerun()

    with col2:
        if st.button("ëŒ€í™” ì‚­ì œ", use_container_width=True):
            if len(st.session_state.conversations) > 1:
                del st.session_state.conversations[st.session_state.current_conv_id]
                st.session_state.current_conv_id = list(st.session_state.conversations.keys())[0]
                st.rerun()
            else:
                st.toast("ìµœì†Œ 1ê°œ ëŒ€í™” ìœ ì§€ í•„ìš”")

    with col3:
        if st.button("ë‹µë³€ ë³µì‚¬", use_container_width=True):
            st.toast("ë³µì‚¬ë¨" if current_conv.get("last_result") else "ë³µì‚¬í•  ë‹µë³€ ì—†ìŒ")

    with col4:
        if st.button("ëŒ€í™” ì €ì¥", use_container_width=True):
            if current_conv["history"]:
                import json
                st.download_button("ë‹¤ìš´ë¡œë“œ", json.dumps({"history": current_conv["history"]}, ensure_ascii=False),
                                  f"ëŒ€í™”_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", "application/json")
            else:
                st.toast("ì €ì¥í•  ëŒ€í™” ì—†ìŒ")
