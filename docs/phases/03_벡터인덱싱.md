# Phase 3: 벡터 인덱싱

> **상태**: ✅ 완료
> **도메인**: 검색 레이어 (Retrieval)
> **목표**: ChromaDB에 청크 임베딩 저장 및 벡터 검색 구현

---

## 1. 개요

Phase 2에서 생성된 텍스트 청크들을 벡터 임베딩으로 변환하고,
ChromaDB에 저장하여 의미 기반 검색이 가능하도록 구성하는 단계.

---

## 2. 태스크

| # | 태스크 | 상태 |
|---|--------|------|
| 1 | Embedding 모델 선정 및 테스트 | ✅ |
| 2 | ChromaDB 설정 (영속 저장소) | ✅ |
| 3 | 청크 임베딩 생성 및 저장 | ✅ |
| 4 | 벡터 검색 함수 구현 | ✅ |
| 5 | 검색 품질 테스트 | ✅ |

---

## 3. 기술 선택

### 3.1 Embedding 모델

| 항목 | 선택 |
|------|------|
| 모델 | OpenAI `text-embedding-3-small` |
| 차원 | 1536 |
| 선택 이유 | 비용 효율적, 품질 우수, 한글 지원 |

### 3.2 벡터 DB

| 항목 | 선택 |
|------|------|
| DB | ChromaDB |
| 저장 방식 | 영속 저장 (persist) |
| 경로 | `stores/chroma/` |
| 선택 이유 | 경량, 설치 간편, Python 친화적 |

---

## 4. 구현

### 4.1 핵심 코드

**임베딩 모듈** (`src/embedding/embedder.py`):
```python
from openai import OpenAI

class Embedder:
    def __init__(self, model: str = "text-embedding-3-small"):
        self.client = OpenAI()
        self.model = model

    def embed(self, text: str) -> List[float]:
        """텍스트를 벡터로 변환"""
        response = self.client.embeddings.create(
            model=self.model,
            input=text
        )
        return response.data[0].embedding

    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """배치 임베딩"""
        response = self.client.embeddings.create(
            model=self.model,
            input=texts
        )
        return [item.embedding for item in response.data]
```

**벡터 스토어** (`src/embedding/vector_store.py`):
```python
import chromadb

class VectorStore:
    def __init__(self, persist_dir: str = "stores/chroma"):
        self.client = chromadb.PersistentClient(path=persist_dir)
        self.collection = self.client.get_or_create_collection(
            name="ur5e_chunks",
            metadata={"hnsw:space": "cosine"}
        )

    def add_documents(self, chunks: List[Chunk], embeddings: List[List[float]]):
        """청크와 임베딩 추가"""
        self.collection.add(
            ids=[c.chunk_id for c in chunks],
            embeddings=embeddings,
            documents=[c.text for c in chunks],
            metadatas=[c.metadata for c in chunks]
        )

    def search(self, query_embedding: List[float], top_k: int = 5) -> List[SearchResult]:
        """벡터 유사도 검색"""
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )
        return self._parse_results(results)
```

### 4.2 인덱싱 프로세스

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│ JSON 청크   │───▶│ Embedder    │───▶│ ChromaDB   │
│ (722개)     │    │ (OpenAI)    │    │ (저장)      │
└─────────────┘    └─────────────┘    └─────────────┘
       │                  │                  │
       ▼                  ▼                  ▼
   텍스트             1536차원 벡터      영속 저장소
```

---

## 5. 산출물

### 5.1 파일 목록

| 파일 | 내용 |
|------|------|
| `stores/chroma/` | ChromaDB 인덱스 (영속) |
| `src/embedding/embedder.py` | 임베딩 모듈 |
| `src/embedding/vector_store.py` | 벡터 스토어 |
| `scripts/index_chunks.py` | 인덱싱 스크립트 |

### 5.2 인덱스 통계

| 항목 | 값 |
|------|-----|
| 총 청크 수 | 722 |
| 벡터 차원 | 1536 |
| 인덱스 크기 | ~15MB |
| 검색 지연 | < 50ms |

---

## 6. 검색 테스트

### 6.1 샘플 쿼리 테스트

| 쿼리 | 상위 결과 | 관련도 |
|------|----------|--------|
| "C154A3 에러" | Error code C154A3... | 0.92 |
| "Control Box 팬 고장" | Fan malfunction... | 0.88 |
| "조인트 5 교체 방법" | Joint 5 replacement... | 0.85 |

### 6.2 Recall@5 초기 측정

| 쿼리 유형 | Recall@5 |
|-----------|----------|
| 에러코드 | ~80% |
| 컴포넌트 | ~75% |
| 일반 질문 | ~70% |

---

## 7. 검증 체크리스트

- [x] 722개 청크 모두 인덱싱 완료
- [x] 벡터 차원 1536 확인
- [x] 코사인 유사도 검색 동작
- [x] 영속 저장소 재시작 후 유지
- [x] 검색 응답 시간 < 100ms

---

## 8. 다음 단계

→ [Phase 04: 온톨로지 설계](04_온톨로지설계.md)

---

**Phase**: 3 / 19
**작성일**: 2026-01-22
